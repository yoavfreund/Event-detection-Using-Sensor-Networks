\section{Target Localization}\label{sec:TL}
%Using Minimal Number of Sensors}

A sensor network consisting of $M$ sensing units aims to capture information of interest (often described in terms of parameters) regarding the physical environment by acquiring measurements in space (dictated by sensor locations) and in time (dictated by the sampling technique employed at each sensor). In many applications (especially those concerning high-resolution/super-resolution imaging), the goal is to detect certain (possibly time varying) parameters $\Theta(\tau)$ from certain targets (or sources) of interest in the environment by acquiring signals emitted by them. The methodologies proposed in this proposal will be primarily developed for passive sensing, although they can also be integrated into an active sensing scenario if the sensors are also allowed to actively emit signals for localizing targets.
%\filcenter
%\yoav{I simplified and shortened the introduction, moving quickly to the example}

As described in the introduction, {\em target localization} is the task of identifying the location of so-called targets. There are two main types of target localization. In {\em passive} localization (e.g., localizing a speaker) we rely on signals generated by the target.   In {\em active} localization (e.g., radar or sonar) we generate signals that are reflected by the target.

As a concrete example, consider a network consisting of active radar units mounted on an autonomous vehicle. The goal of the system is to detect and track pedestrians, bicyclists and other cars in the vicinity of the AV. For simplicity, lets assume that we refer to any of these objects as a {\em target} and assume that we have $K$ targets. Let the state of target $i$, denoted $\theta_i$ be defined by the 2d location and 2d velocity of the target. The task of our tracking system is to estimate the number of targets and the state of each target.
The combined state $\Theta$ is defined as 
\begin{equation} \Theta = [K, \{x_i, y_i, vx_i ,vy_i\}_{i=1}^K]^T 
\end{equation} 
Mathematically the space-time measurements collected at the $m$th sensing element can be described as 
\begin{equation} 
y_m (t) = \sum_{i=1}^{K} \phi (\mathbf{d}_m,\theta_i,t) + w_m(t), \quad 1\leq m\leq M 
\label{eqn:MeasMod}\end{equation}
where $w_m(t)$ is additive noise. Here $\mathbf{d}_m\in \mathbb{R}^3$ denotes the location of the $m$th sensor and the function $\phi(.)$ characterizes the measurement model (often referred to as the point-spread function in the context of imaging) that depends on the physical laws governing wave propagation, and properties of the medium. The transfer function is simple in open-air far-field scenarios such as open-air radar. The transfer funcion becomes very complex in confounded near-field scenario such as audio localization in a small room.

% Depending on the application and model assumptions, the function $\phi(.)$ can be linear, non-linear, and potentially, even non-convex. However, it can be {\em partially designed} by choice of sensor locations $\mathbf{d}_m$. This will be a key enabler towards obtaining compressed sketches of measurements (or reducing the number of sensing units) while preserving the ability to reliably infer the parameter $\Theta(\tau)$.\\

%The basic model assumes targets as point sources, but in many %situations, they are distributed. \piya{Perhaps Peter can help %characterize this model, since SONAR deals with such targets}. 

% \yoav{I found the following paragraph confusing. Are you talking about how to process $Y$ or are you talking about how to select coordinates of $Y$?}

% The main objective is to obtain estimates $\hat\Theta(\tau)$ of the parameter of interest $\Theta (\tau)$ using {\em minimal number of measurements/minimizing the number of sensing elements}. These estimates essentially are some appropriate functions of the spatio-temporal measurements $\mathbf{Y} = \{y_m(t),  1\leq m\leq M, 1\leq t\leq T \}$, i.e., 
% \begin{equation}
% \hat{\Theta}(T) = \mathbf{g} (\mathbf{Y}) 
% \end{equation} 
% In passive localization, $\hat{\Theta}(T)$ is typically a function of the {\em cross correlation} between sensor measurements. In other words, the function $\mathbf{g}$ can be composed as $\mathbf{g}=\mathbf{g}_1 \circ \mathbf{g}_2$ where $\mathbf{g}_2(\mathbf{Y})=\frac{1}{T}\mathbf{YY}^{H}$. Hence, it is important to understand how the sensing geometry influences our estimate of the parameter via such quadratic correlation maps.

% \yoav{I think sections 3.1 and 4 should be shortened and merged. Section 5 is the meat : Difference sets and their use for sensor placement.  The difference sets needs a clearer presentation. On the other hand, I would remove most of the detailed equations: 11,12,14. I would keep eqn 13. Then I would list, in bullet form the main cases that Piya has already solved. As for the tomography section. It needs an introduction}
% \subsection{Correlation-Based Passive Localization and Geometry of Sensing:} 

In many scenarios, the quantities of interest can be estimated from the {\em correlation of the measurements}. In other words, the correlation of the measurements acts as a sufficient statistic for the parameters to be inferred. Depending on the application, the correlation matrix can be spatial (when the source signals are stationary), or spatio-temporal (when the temporal dynamics need to be tracked, such as for change-point detection). In fact, the majority of passive sensing and localization techniques heavily rely upon computing cross correlation between sensor measurements to estimate location parameters. In these cases, we can effectively summarize the large amount of raw sensor data by only retaining and communicating their correlation. 
% \yoav{The way I was thinking about it, each sensor has only one signal. In a one scenario, the quantity of interest is the "time delay of arrival" or the time shift of one signal relative to another that would maximize the correlation. Is there anything known about computing this time delay without communicating the whole time series?}
% \piya{Since this is passive localization based on narrowband signals (or wideband signals decomposed into narrow frequency bins), the time delay of arrival translates to phase offset across the array. One sensor can localize two targets, but it takes more than two sensors to localize multiple targets}

 Suppose we compute the empirical spatial correlation between $y_m(t)$ and $y_n(t)$  by averaging over $T$ time samples (the signals are assumed to be stationary over this interval) %\footnote{Reasonable to do so when the source signals are stationary and emit independent signals. This is the common practice in source localization using antenna arrays. We can also use more sophisticated regularized estimation of correlation.}
\begin{equation}
\mathbf{\hat{R}}_{m,n} = \frac{1}{T}\sum_{t=1}^{T} y_m (t) y^*_n (t)  \label{eq:corr}
\end{equation} 
We can summarize the self and cross correlation between $M$ time-series measurements (collected at $M$ sensors) using $M^2$ correlation values (written as a correlation matrix $\mathbf{\hat{R}}$). Owing to the geometry of the measurements, these correlation values directly depend on the sensor locations $\mathbf{d}_m$  (via the mapping $\phi(.)$). We will utilize this dependence of the correlation matrix on the underlying sensor geometry to achieve the following goals:

%We consider three ways of utilizing the correlation matrix. 
\piya{I changed previous sub-tasks. DOA estimation is only part of prior work, not proposed. I rewrote to keep sensor subset selection and add localization of weak sources and tomography (Peter's items) with brief descriptions for each.}
\begin{enumerate}
\item {\bf Selecting Subset of Communicating Sensors:} A goal  is understanding which subset of sensors should communicate  in a distributed setting without degrading the localization performance. Since majority of passive localization algorithms utilize the cross correlation between sensor pairs, the main idea  is to exploit inherent redundancies present in these cross correlation values to reduce the number of communicating sensors. Thus, via sensor subset selection, we will obtain a compressive but lossless sketch of the larger correlation matrix consisting of all possible correlation pairs. In Sec. \ref{sec:SensorSelection}, we will build on Co-PI Pal's recent work on Generalized Nested Sampling (GNS) to perform such subset selection in two dimensions.
%that can be studied using the correlation matrix is whether there is redundancy among the sensors. Such redundancy can be exploited to turn off some of the sensors without significantly degrading the localization performance. PI Pals work in this area is described in Section~\ref{sec:sensorSelection}, as is our proposed work.
%\item {\bf Determining direction of arrival (DOA):} In this well studied scenario a single target is located far from all of the sensors. Here, the correlation matrix is fully determined by the direction vector from the sensors to the target. A simple  transformation of the correlation can be used to determine the direction.
\item {\bf Localization of Weak Sources:} \piya{Peter: Change wording so it blends well with graph signal processing} In this case the target is located between the sensors. In addition, the signal generated by the target is faint. The correlation matrix is more complex as only those sensors that are close to the target capture a sufficiently strong signal and the correlation is a non-linear function of the target location. In Sec.~\ref{sec:weakSources} we describe  this problem, and outline our proposed work.

\end{enumerate}

\subsection{Localizing weak sources with graph signal processing}
 \label{sec:weakSources}
The focus here is to detect weak sources within a sensor network without a fusion center. A source is said to be weak if it is only seen on a subset of the network. To observe weak sources, as much information as possible should be used. Thus, at first we will not compress the data by sketching or special sensor arrangements. The network could consist of sensors with known, partially unknown or completely unknown positions. We will first consider weak narrow band sources, but later generalize to broadband sources. For broadband sources, care will be taken so that that non-informative frequency bands (such as those with low signal-to-noise ratio) do not contaminate the results.

% The propagation path from a given source location would here represent multiple propagation paths in a non-uniform media. The frequency domain transfer function from a source location to $N$ receivers ${\bf a}$. Assuming $K$ uncorrelated sources of complex amplitude ${\bf s}$ at spatial location ${\bf x}_k$, the received signal ${\bf y}\in {\cal R}^N$ on $N$ receivers is 
% \begin{equation}
% {\bf y}={\bf A}{\bf s}+{\bf n},
% \end{equation}
% where ${\bf A}=[{\bf a}_1, \ldots {\bf a}_K ]$  and $\bf n$ is uncorrelated noise. 
% Here ${\bf x}_k$ and is the spatial location of the source and $a_k\in {\cal R}^N$ is the propagation from source $k$ to the $N$ receivers. 
% In the far-field and free space, ${\bf x}_k$ is determined by the phase delay 
% $e^{\imath \omega \|{\bf x}_n-{\bf x}_k\|/c}$ 
% ($c$ is sound speed, $\omega$ frequency, and $\|{\bf x}_n-{\bf x}_k\|$ is distance between source $k$ and receiver $n$). 
% We will here operate in the near field and more complicated environments, so this simple relation might not hold.

% The sources might be located in the near field and  composed of many propagation paths. Examples of many propagation paths from a single source could be waves from  
% 1) a source in a house propagating though the air and though the wall.
% 2) a cell phone signal with a direct path, a reflected path or refracted path.
% 3) a car radiating noise though the air and though the ground.
% Further, the sensors are not placed in a regular order, but where practical and maybe with unknown location. Thus the elements in ${\bf a}_k$ are unknown.

A graph signal processing approach was used in \cite{riahi2017} for a 5000 element seismic array by processing the whole narrow band and normalized $\hat{\bf R}$ \eqref{eq:corr} at once, i.e., using a fusion center. We normalize 
$\hat{\bf R}$ to form a correlation matrix. %We normalize the The narrow band normalized SCM is here a coherence matrix.
Using hypothesis testing, when the  normalized $\hat{\bf R }$ is above a certain threshold at  element $ij$, it is likely that a signal has propagated between nodes $i$ and $j$, essentially forming an edge between nodes  $i$ and $j$ in a graph. Similar processing will be done for neighboring nodes $i$ and $k$. The information of connected nodes will be shared in a region. When a sufficient set of connected edges are detected in a region of the network, a source is likely in that region. Part of the extracted normalized $\hat{\bf R}$ for that region can then be used to localize the source more precisely.

To extract very weak signals a robust estimate of correlation matrix \eqref{eq:corr} is needed.  Thus we  pass the full time series between local nodes $i$ and $j$, not the whole array and develop robust signal processing methods \cite{zoubir2018}. This will require a lot of communication demand and thus we will only share signals between neighboring stations. Once a graph edge is formed it could  be either communicated further to a wider set of nodes, or it could be passed to a central fusion center for further processing. 

Robust signal processing methods \cite{zoubir2018} will be developed to make the processing insensitive to outliers. Qualitative robustness can be investigated via the influence function. The influence function  of an estimator 
measures the sensitivity to a slight change in the distribution
in the neighborhood of the nominal distribution of the observations. 
A qualitatively robust estimator is characterized by an influence function that is continuous and bounded. Continuity implies that small changes in the observed sample cause only small changes in the estimate. The boundedness implies that a small amount of contamination cannot lead to an unbounded error the estimate.

We propose to work on:
(1) A scheme for processing locally at each node. 
(2) Estimate of the SCM should be robust to outliers \cite{zoubir2018}. Thus we will investigate the processing for empirical influence functions.  %Kernelized methods could likely increase the robustness, see Section \ref{sec:KernelBackground}. \alex{Is the sentence true?}
(3) Extract relevant physical signals that can be used in the extraction of environmental parameters $\bf E$.

%\yoav{What is the relationship between $a_k$ and $x_k$?}

% To make observations of weak sources we observe $L$ snapshots  assuming  stationarity ${\bf Y}=[{\bf y}_1 \ldots {\bf y}_L]$.
% We can here form the sample covariance matrix (SCM)
% \begin{equation}
% {\bf S} ={\bf Y}{\bf Y}^H/L
% \end{equation}
% and form the the normalized SCM $\hat{\bf S}$ or coherence with elements
% \begin{equation}
% \hat{ S}_{ji} =\frac{{ S}_{ji}}{\sqrt{ { S}_{ii}{ S}_{jj}}}
% \end{equation}

% \yoav{I am confused about the definition of coherence, should it not be the maximum correlation when one signal to be shifted relative to the other?}

% Forming the ensemble mean over multiple snapshots give the cross spectral density matrix${\bf C}\in {\cal R}^N\times N$
% \begin{equation}
% {\bf C}={\cal E}[{\bf y} {\bf y}^H]= {\bf A}{\bf s}{\bf s}^H{\bf A}^H+{\bf N},
% \end{equation}

%The array signal processing literature is ample with processing of this type, especially with the structure of the $\bf A$ matrix partially known. In this work we will focus on pushing the computations to the sensor nodes and thus only observing part of SCM.

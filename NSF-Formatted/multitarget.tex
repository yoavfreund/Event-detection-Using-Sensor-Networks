\section{Passive narrow-band multi-target localization (Piya)}
\yoav{How is this problem different from the problem of finding the
  best placement for the sensors in order to maximize the accuracy of
  localization, ignoring communication bendwidth?}

With the aim of obtaining a compressive sketch of the correlation matrix (also termed as compressive covariance sensing), we will optimize the design of sensor array (i.e. choice of $\mathbf{d}_m, 1\leq m\leq M$) by understanding how the array geometry controls the algebraic structure of $R_T$. One of the main objectives will be to understand how much communication is needed (and between which subset of sensors) to achieve a certain level of accuracy. To illustrate this, we briefly discuss Co-PI Pal's recent work in structured sampler design (e.g., nested, coprime and generalized nested samplers) which utilize the idea of difference sets.

\begin{itemize}
\item {\bf Difference set-inspired Designs:} I will review some results in the context of array processing and DOA estimation...(to be filled in).
\item {\bf Proposed Research:} Motivated by these results, our goal will be to develop a rigorous framework for further developing the key idea of correlation-aware sensing to a distributed scenario and make it applicable for imaging problems beyond point target localization.
\begin{enumerate}
\item {\bf Distributed Sensing:} The idea of difference set inspired sampler design can be actually generalized beyond that of antenna arrays, to acquire {\em compressive sketches} of the correlation between signals acquired between pairs of sensors. In general, given $N$ sensors, it is natural to think that one needs to compute the correlation between all $N\choose 2$ time series (from all possible sensor-pairs) to construct the overall $N\times N$ correlation matrix $R_T$. However, using the idea of difference-set sampling, one can only compute  cross-correlation values between a much smaller subset of size $\Theta(\sqrt{N})$ of {\em suitably selected sensor-pairs} and recreate the entire $N\times N$ correlation matrix $R_T$. In the context of distributed sensing, this automatically means that only these sensors need to communicate and exchange information.

{\em Exploiting Distance-based Redundancies:} The key idea behind achieving such reduction is to exploit the redundancies present in the correlation values that naturally result from the physical spatial signal model. A widely used example of such a redundancy is that the correlation $r_{m,n} = E\Big(y_m(t)y^*_n(t)\Big)$ between $m$th and $n$th sensors is of the following form \begin{equation} r_{m,n} \approx f(\mathbf{d}_m - \mathbf{d_n}) \label{eqn:CorrRed}\end{equation}
In other words, the correlation is spatially only a function of the {\em inter-sensor distance}, and this is a direct consequence of the functional form of $\phi(.)$ \piya{Can give specific examples if needed}. This is also referred to as spatial stationarity and it is (exactly or approximately) true for many applications as narrowband and wideband radar \footnote{In the latter case, this holds at individual frequency bands after splitting the wideband signal into narrow frequency bins using a filter bank}, super-resolution optical imaging \cite{}, mmWave wireless channels \cite{} and so forth. Hence, depending on the inter-sensor distances, many of these $N\choose 2$ correlation values are actually repeated/redundant. Based on this observation, we propose to use a new sketching technique developed by co-PI Pal, called {\bf Generalized Nested Sampling (GNS) to reduce the amount of inter-sensor communication}. Suppose the sensors are located on a uniform grid. In one dimension, (\ref{eqn:CorrRed}) implies that the correlation matrix $R_T$ has Toeplitz structure and GNS provides an optimal way to select sensors to sketch such a matrix. 
\begin{definition}\piya{Definition of GNS goes here..}
\end{definition}
Hence, GNS dictates how to select a subset $\mathcal{S}_{\text{GNS}}$ of $M =  = \Theta(\sqrt{N})$ sensors out of $N$ available sensors. Let $R_{\mathcal{S}} \in \mathbb{C}^{M\times M}$ be the correlation matrix computed by aggregating the signals from these sensors. Then GNS ensures that $R_{\mathcal{S}}$ is a {\em lossless} sketch of the high-dimensional correlation matrix $R_T$. \piya{To Add (i) Finite sample performance guarantees (ii) two and three-dimensional extension (iii) low-rank extension and (iv) Time-varying model.}


%Will focus on what subsets of sensors in a distributed setting should communicate to be able to reconstruct the source scene. Can think of a subset of spatially close sensors to fully communicate with each other (assuming cost of communication proportional to proximity/distance), and then transmit the sketch / coarse parameter estimates (or their binarized measurement) to the sensors further away. Can lead to interesting hierarchical configurations for distributed sensors, dictated by $\phi(.)$. {\color{red} [To Add more Details..]}.
%\yoav{I think this is a very interesting question. Especially when the best subset depends on the location of the source.}\rayan{agree!}
\item {\em Beyond Point Target Localization: Using Priors and Sparsity} In many applications such as camera networks, the quantities of interest are not the low-level measurements acquired at the CCD sensors, but the processed images $I_t$. In such cases, we need to obtain a compressive sketch of the image $A (I_t)$ via the sketching operator $A (.)$ using low dimensional representation (over unions of subspaces or manifolds). In addition to conventional sparsity and low-rank priors, one can also utilize (partial) knowledge of the prior distribution of the images $I_t\sim~\mathcal{D}$. Utilizing these priors can lead to more effective compression for a given level of sparsity. {\color{red} [To be written..]}  
\end{enumerate}
\piya{These tasks can be further integrated with the binary embedding based sketching ideas proposed by Rayan and Alex.}
\rayan{Agree!}
\end{itemize}

\subsection{Graph signal processing approach without a fusion center}
\yoav{I think this section can be combined with Piya's
  sections. Choosing which pairs should communicate is clearly related
  to their geometric layout.}

Here the processing is done locally at each node. A graph signal processing approach was used in Ref \cite{riahi2017} for a 5000 element seismic array by processing the whole normalized SCM at once, i.e., using a fusion center. 
When the coherence $\hat{\bf S}$ is above a certain threshold at  element $ij$ it is likely that a signal is observed and has propagated between nodes $i$ and $j$, essentially forming an edge between nodes  $i$ and $j$ in a graph. When a sufficient set of connected edges are detected in a region of the network a source is likely in that region. Part of the extracted SCM can then be used localize the source more precisely.

To extract very weak signals with a well estimated and robust SCM is needed. Thus we  pass the full time series between local nodes $i$ and $j$, not the whole array and develop robust signal processing methods\cite{zoubir2018}. This will represent a lot of communication demand and thus we will only pass signal between neighboring stations. Once a graph edge is formed it could either be communicated further to a wider set of nodes.

Robust signal processing methods\cite{zoubir2018} would entail making the processing insensitive to outliers. Qualitative robustness can be investigated via the influence function. A qualitatively robust estimator is characterized by an IF that is continuous and bounded. Continuity implies that small changes in the observed sample cause only small changes in the estimate. The boundedness implies that a small amount of contamination cannot lead to an unbounded error the estimate.

\section{Passive Narrow-band Multi-Target Localization With Distributed Sensors (Piya)}
\yoav{How is this problem different from the problem of finding the
  best placement for the sensors in order to maximize the accuracy of
  localization, ignoring communication bendwidth? }

With the aim of obtaining a compressive sketch of the correlation matrix (also termed as compressive covariance sensing), we will optimize the design of sensor array (i.e. choice of $\mathbf{d}_m, 1\leq m\leq M$) by understanding how the array geometry controls the algebraic structure of $R_T$. One of the main objectives will be to understand how much communication is needed (and between which subset of sensors) to achieve a certain level of accuracy. To illustrate this, we briefly discuss Co-PI Pal's recent work in structured sampler design (e.g., nested, coprime and generalized nested samplers) which utilize the idea of difference sets.

\subsection{Background and Prior Work: Difference Set-Inspired Designs:} 
I will review some results in the context of array processing and DOA estimation...(to be filled in).
\subsection{Proposed Research: Correlation-Aware Sensor Selection for Distributed Sensing} Motivated by these results, our goal will be to develop a rigorous framework for further developing the key idea of correlation-aware sensing to a distributed scenario and make it applicable for imaging problems beyond point target localization.
The idea of difference set inspired sampler design can be actually generalized beyond that of antenna arrays, to acquire {\em compressive sketches} of the correlation between signals acquired between pairs of sensors. In general, given $N$ sensors, it is natural to think that one needs to compute the correlation between all $N\choose 2$ time series (from all possible sensor-pairs) to construct the overall $N\times N$ correlation matrix $\mathbf{R}$ \footnote{$\mathbf{R}$ represents the ideal correlation matrix, whereas $\mathbf{\hat{R}}$ represents an estimate of $\mathbf{R}$ computed with finite data}. However, using the idea of difference-set sampling, one can only compute  cross-correlation values between a much smaller subset of size $\sim\sqrt{N}$ of {\em suitably selected sensor-pairs} and recreate the entire $N\times N$ correlation matrix $\mathbf{R}$. In the context of distributed sensing, this automatically means that only these sensors need to communicate and exchange information.

{\bf Key Idea: Exploiting Distance-based Redundancies Using Generalized Nested Samplers:} The main idea behind achieving such reduction is to exploit the redundancies present in the correlation values that naturally result from the physical spatial signal model. A widely used example of such a redundancy is that the correlation $\mathbf{R}_{m,n} = E\Big(y_m(t)y^*_n(t)\Big)$ between $m$th and $n$th sensors is of the following form \begin{equation} \mathbf{R}_{m,n} \approx f(\mathbf{d}_m - \mathbf{d_n}) \label{eqn:CorrRed}\end{equation}
In other words, the correlation is spatially only a function of the {\em inter-sensor displacement $\mathbf{d}_m - \mathbf{d_n}$}, and this is a direct consequence of the functional form of $\phi(.)$ \piya{Can give specific examples if needed}. This is also referred to as spatial stationarity and it is (exactly or approximately) true for many applications as narrowband and wideband radar \footnote{In the latter case, this holds at individual frequency bands after splitting the wideband signal into narrow frequency bins using a filter bank}, super-resolution optical imaging \cite{}, mmWave wireless channels \cite{} and so forth. Hence, depending on the inter-sensor distances, many of these $N\choose 2$ correlation values are actually repeated/redundant. Based on this observation, we propose to use a new sketching technique developed by co-PI Pal, called {\bf Generalized Nested Sampling (GNS) to reduce the amount of inter-sensor communication}. Suppose the sensors are located on a uniform grid. In one dimension, (\ref{eqn:CorrRed}) implies that the ideal correlation matrix $\mathbf{R}$ has Toeplitz structure and GNS provides an optimal way to select sensors to sketch such a matrix. Given any integer $L\ge 6$, GNS is defined in terms of two integer valued parameters $\Theta(N)$ and $\Gamma(N)$ given by
\begin{equation} \Theta(N) = \lfloor \sqrt{N + \frac{1}{4}} - \frac{1}{2} \rfloor \quad 
\Gamma(N)=1+L-{\Theta}^2(N) 
\end{equation}
%The sampling matrix $\mathbf{A}$ called "Generalized Nested Sampling Matrix" in \cite{HP_GSip} is defined by
Given $\Theta(N)$ and $\Gamma(N)$, a GNS can be defined as the following measurement/sensor-selection matrix
\begin{definition} For any integer $N \ge 6$, a Generalized Nested Sampling matrix $\mathbf{A}_{\text{GNS}} \in \mathbb{R}^{M \times N}$, with $M = \Gamma(N) + \Theta(N) - 1$ is given by 

\begin{equation}
 [\mathbf{A}_{\text{GNS}}]_{i,j}= \begin{cases}  1 & \textrm{if} \; j = i,\; 1 \le i \le \Gamma(N) \\
1 & \textrm{if} \; j=(i-\Gamma(N))\Theta(N)+i, \quad \Gamma(N) < i \le M  \\
0 &  \text{else}
\end{cases}
\label{def_A}
\end{equation}
\end{definition}
It can be noted that $\mathbf{A}_{\text{GNS}}$ is essentially a {\em row-selection} matrix that selects $M$ out of $N$ elements of a vector. The indices of these $M$ rows crucially tell us {\em which sensors to select} so that we can obtain a lossless sketch of $\mathbf{R}$ by computing the cross-correlation between these $M$ sensors. Such selection is governed by the need to exploit distance-based redundancies as captured in (\ref{eqn:CorrRed}). As discussed earlier, when the sensors are located on a one uniform dimensional grid, (\ref{eqn:CorrRed}) essentially implies that the full correlation matrix $\mathbf{R}$ is a Toeplitz matrix. %GNS dictates how to select a subset of $M$ sensors which maximally exploit the redundancies in a Toeplitz $\mathbf{R}$. 
%the number of rows of $\mathbf{A}_{\text{GNS}}$ scales . The specific case of $L=M^{2}/4+M/2-1$ was introduced as ``Nested Array" in \cite{PiyaNested}. As discussed in \cite{HP_GSip}, the fundamental idea behind GNS or other sparse ruler type sampler is to exploit the difference set of the sampling indices. In particular, each row of $\mathbf{A}_{s}$ contains a single $1$ and let $c(i)$ denote the index of the column containing it. Then, the $(i,j)$th entry of $\mathbf{R_Y}$ corresponds to $t_{c(i)-c(j)}$. The length of smallest range over which $(i,j)$ should be chosen so that $\{c(i)-c(j)\}$ spans all integers from $0$ to $L-1$ is $O(\sqrt{L})$ and the GNS shows a constructive way to select $c(i)$ over this range.
%\end{remark}
%%The following result from \cite{HP_GSip} shows how to compress a $N\times N$ Toeplitz matrix without assuming it to be low rank.
%\begin{lem}
%A real symmetric Toeplitz matrix $\mathbf{T}\in \mathbb{R}^{N \times N}$ can be exactly recovered from its compressed measurement $\mathbf{R_Y}=\mathbf{A}_{GNS}^{N} \mathbf{T}(\mathbf{A}_{GNS}^{N})^{T}$ where $\mathbf{A}_{GNS}^{N}\in \mathbb{R}^{M \times N}$ is a Generalized Nested Sampling Matrix given by (\ref{def_A}).
%\label{lem:general}
%\end{lem}
%\end{definition}
Hence, GNS dictates how to select a subset $\mathcal{S}_{\text{GNS}}$ of $M =  = \Theta(\sqrt{N})$ sensors out of $N$ available sensors so that the Toeplitz $\mathbf{R}$ can be {\em exactly reconstructed} from the pair-wise correlation between sensors in $\mathcal{S}_{\text{GNS}}$. Let $\mathbf{R}_{\mathcal{S}_{\text{GNS}}} \in \mathbb{C}^{M\times M}$ be the correlation matrix computed by aggregating the signals from these sensors. Then, we have 
\begin{equation}
\mathbf{R}_{\mathcal{S}_{\text{GNS}}} = \mathbf{A}_{\text{GNS}} \mathbf{R} \mathbf{A}^T_{\text{GNS}} 
\end{equation}
The structure of $\mathbf{A}_{\text{GNS}}$ ensures that $\mathbf{R}_{\mathcal{S}}$ is a {\em lossless} sketch of the high-dimensional correlation matrix $\mathbf{R}$. 

%\piya{To Add (i) Finite sample performance guarantees (ii) two and three-dimensional extension: Subsets of regions where targets are tracked, split into regions where GNS is employed to reconstruct the individual scenes (Cellular system like), (iii) Wideband Signals (iv) Time-varying model.}


%Will focus on what subsets of sensors in a distributed setting should communicate to be able to reconstruct the source scene. Can think of a subset of spatially close sensors to fully communicate with each other (assuming cost of communication proportional to proximity/distance), and then transmit the sketch / coarse parameter estimates (or their binarized measurement) to the sensors further away. Can lead to interesting hierarchical configurations for distributed sensors, dictated by $\phi(.)$. {\color{red} [To Add more Details..]}.
%\yoav{I think this is a very interesting question. Especially when the best subset depends on the location of the source.}\rayan{agree!}
%\item {\em Beyond Point Target Localization: Using Priors and Sparsity} In many applications such as camera networks, the quantities of interest are not the low-level measurements acquired at the CCD sensors, but the processed images $I_t$. In such cases, we need to obtain a compressive sketch of the image $A (I_t)$ via the sketching operator $A (.)$ using low dimensional representation (over unions of subspaces or manifolds). In addition to conventional sparsity and low-rank priors, one can also utilize (partial) knowledge of the prior distribution of the images $I_t\sim~\mathcal{D}$. Utilizing these priors can lead to more effective compression for a given level of sparsity. {\color{red} [To be written..]}  
%\end{enumerate}
\piya{These tasks can be further integrated with the binary embedding based sketching ideas proposed by Rayan and Alex.}
\rayan{Agree!}
\end{itemize}

\subsection{Graph signal processing approach without a fusion center}
\yoav{I think this section can be combined with Piya's
  sections. Choosing which pairs should communicate is clearly related
  to their geometric layout.}

Here the processing is done locally at each node. A graph signal processing approach was used in Ref \cite{riahi2017} for a 5000 element seismic array by processing the whole normalized SCM at once, i.e., using a fusion center. 
When the coherence $\hat{\bf S}$ is above a certain threshold at  element $ij$ it is likely that a signal is observed and has propagated between nodes $i$ and $j$, essentially forming an edge between nodes  $i$ and $j$ in a graph. When a sufficient set of connected edges are detected in a region of the network a source is likely in that region. Part of the extracted SCM can then be used localize the source more precisely.

To extract very weak signals with a well estimated and robust SCM is needed. Thus we  pass the full time series between local nodes $i$ and $j$, not the whole array and develop robust signal processing methods\cite{zoubir2018}. This will represent a lot of communication demand and thus we will only pass signal between neighboring stations. Once a graph edge is formed it could either be communicated further to a wider set of nodes.

Robust signal processing methods\cite{zoubir2018} would entail making the processing insensitive to outliers. Qualitative robustness can be investigated via the influence function. A qualitatively robust estimator is characterized by an IF that is continuous and bounded. Continuity implies that small changes in the observed sample cause only small changes in the estimate. The boundedness implies that a small amount of contamination cannot lead to an unbounded error the estimate.

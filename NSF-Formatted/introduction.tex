\section{Introduction}
There are good reasons humans have {\em two} eyes and {\em two}
ears. Our two eyes provide us with depth perception. Our two ears
allow us to detect the direction from which a sound is coming.

The same applied to artificial sensors. Multiple sensors with
overlapping receptive fields can produce better representations of the
environment. However, to produce such representations, the data
streams generated by the sensors need to be compared and combined. One
approach is to send all of the signal to a center and use a single
computer to combined them. This approach requires high bandwidth
communication and powerful computers and does not scale well to
networks with hundreds or thousands of sensors.


An alternative is {\em pushing computation to the edge}. Instead of
performing all of the computation on a central machine, each sensor
has some computing power which it uses to perform some of the
computation and reduce the amount of information that needs to be
sent. This reduction is not compressionas we are not asking for a
reconstruction of the original signal. Instead what we want to produce
is a high-level representation of the environment. For example, the
location of an object, or a count of the people in a particular
area. Computing this high level representation will usually require
much less information from each sensors than a compressed version of
the raw signal.

We propose a novel approach we call {\em Learning Sensor Networks}.
This approach assumes that sensors are placed at fixed locations and
remain there for a significant length of time.
Each sensor uses {\em statistical learning} to model it's
environment. It communicates with neighboring sensors in order to know
their models and to calibrate parameters such as relative
location. After an initial training period, which might last minutes,
days or months depending on the context, the network can distinguish
normal from abnormal behaviour. Based on that ability, it will
transmit to the other sensors only a {\em sketch}~\cite{} which captures the
novel, or salient aspect of the signals.

Learning sensor networks promise much lower energy and bandwidth
consumption than current sensor networks. To realize this potential we
plan to develop new new mathematical models, signal processing
methods and distributed algorithms for computing and combining
sketches. 



\section{Introduction}
Any agent, be it a human, an animal or a robot, has to react to its
environment to take advantage of opportunities and to avoid
dangers. The transformation of events to reaction can be partitioned
into three steps: {\bf(1)} {\bf physical events} are transformed by
sensors into {\bf raw data}, {\bf (2)} Computation transforms the {\bf
  raw data} into {\bf knowledge} (a representation of the
environment), and {\bf (3)} an {\bf action} is chosen based on the
acquired {\bf knowledge}.

%\rayan{I think we need to edit this a little. The first and second paragraphs feel disconnected from each other.}
%\yoav{Rayan. I agree. See if the paragraph I added improves the flow.  Feel free to edit.}

When detecting and localizing physical events there are significant
advantages to using multiple sensors at different
locations. That is why mammals usually have {\em two} eyes and {\em two}
ears. Two eyes provide depth perception, while two ears
provide directionality. These
abilities are based on {\em comparing} the signals arriving at multiple sensors. 
Comparing signals requires, in turn, {\em
  communication} between the sensors.

Moving from natural to artificial sensors. One is often interested in
detecting and tracking events over a large area, such as a house or a
city. In such cases there is an additional reason to deploying
multiple sensors: sensors typically have a finite range. Therefore the
number of sensors we need is proportional to the area we wish to
cover.

The result of these trends is a rapidly increasing deployment of
{\em  sensor networks}. These are composed
of a large number of sensors, connected by a communication network.

The design of individual sensors is dominated by considerations of
sensitivity and resolution, both temporal and spatial.  The goal is to
detect the smallest, faintest and most transient signals, by
exploiting priors on the physical model of signal propagation and
information on the location of the sensors. Computation is carried out
on each sensor to identify significant events and to correlated them
with events identified on other sensors.

These days the leading architecture of reactive systems is wireless
sensor networks consisting of large numbers of small
independent units, each with sensors, computation and wireless
communication. These systems are constrained by power and communication
bandwidth.

One important consequence of these constraints is {\em pushing
  computation to the edge}. The traditional approach is that the raw data is transmitted from each sensor to a central computer where all computation is done. This approach, while easy to conceptualize, is very inefficient in its utilization of resources, in particular energy, communication bandwidth and computation resources.
  
Due to these constraints,  modern sensor networks must push more communication and computation to the {\em edge} of the network, i.e. the sensor unit. Each sensor unit
locally computes summaries, or sketches, which are shorter and
therefore cheaper to communicate. Sketches are propagated locally and combined with each other to construct a representation of the events in the environment. 

This approach scales much better and conserves energy and communication bandwidth. On the other hand, it requires new distributed algorithms for computing and combining sketches. It is these challenges which we plan to address in the proposed work.


